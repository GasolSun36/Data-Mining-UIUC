1
00:00:00,012 --> 00:00:04,920
[声音]
翻译: PeiyS |审阅:
Coursera Global Translator Community

2
00:00:07,211 --> 00:00:10,243
这节课是关于如何使用时间序列

3
00:00:10,243 --> 00:00:14,870
作为背景
识别文本中潜在的因果话题

4
00:00:14,870 --> 00:00:18,500
这节课我们继续
讨论背景文本挖掘

5
00:00:18,500 --> 00:00:23,390
我们将重点关注
将时间序列作为背景

6
00:00:23,390 --> 00:00:27,600
加入文本分析当中
识别因果话题

7
00:00:27,600 --> 00:00:29,570
像往常一样我们要从动机讲起

8
00:00:29,570 --> 00:00:34,450
这里我们希望利用文本挖掘
理解一个时间序列

9
00:00:34,450 --> 00:00:39,430
这里你看到的是
道琼斯工业平均股价曲线

10
00:00:39,430 --> 00:00:41,775
你能看到这里有个突然的下跌

11
00:00:41,775 --> 00:00:42,600
好

12
00:00:42,600 --> 00:00:45,750
可能有人就会想知道
是什么原因导致了

13
00:00:45,750 --> 00:00:46,530
股市的崩溃

14
00:00:48,870 --> 00:00:51,760
如果你了解背景
你可能能想到

15
00:00:51,760 --> 00:00:56,180
如果看了时间标记
或是其他有帮助的数据的话

16
00:00:56,180 --> 00:01:00,390
但是问题来了
我们能否

17
00:01:00,390 --> 00:01:02,760
从伴随的新闻流找到一些线索呢？

18
00:01:02,760 --> 00:01:06,270
我们有许多在此期间的新闻数据

19
00:01:08,190 --> 00:01:12,120
所以如果你这样做
我们或许能找到原因

20
00:01:12,120 --> 00:01:16,480
在事发后
就是911袭击的时间

21
00:01:16,480 --> 00:01:21,270
也是新闻中911袭击

22
00:01:21,270 --> 00:01:23,840
这一话题突然增加的时间

23
00:01:26,100 --> 00:01:32,020
有另外一个情境我们可以分析
那就是总统选举

24
00:01:32,020 --> 00:01:36,792
这个是时间序列的数据
关于总统预测市场状况的

25
00:01:36,792 --> 00:01:44,980
比如我列出了一系列市场
每个竞选人会有一定的股票

26
00:01:44,980 --> 00:01:49,660
如果你认为其中一个人会赢
你会倾向于为这个人买股票

27
00:01:49,660 --> 00:01:53,970
这个竞选人的价格就会增长

28
00:01:53,970 --> 00:01:58,170
那么就有这样一种方式

29
00:01:58,170 --> 00:01:59,000
可以对人们针对竞选者的意见进行调查

30
00:02:00,440 --> 00:02:05,280
现在假设你看到一个竞选人的价格下降了

31
00:02:05,280 --> 00:02:08,880
你可能想知道
是什么原因导致了价格的下降

32
00:02:10,290 --> 00:02:16,140
或者在社会科学的研究中
你可能有兴趣知道

33
00:02:16,140 --> 00:02:20,930
选举中涉及了什么方法
哪些议题与人民真正相关

34
00:02:20,930 --> 00:02:21,850
目前这个案例里

35
00:02:21,850 --> 00:02:25,370
我们可以从伴随的信息流
来回答这个问题

36
00:02:25,370 --> 00:02:30,010
在信息流当中
能不能找到些线索呢？

37
00:02:30,010 --> 00:02:32,960
比如我们看到了对减税的提及

38
00:02:35,750 --> 00:02:38,360
在这个时候也增加了

39
00:02:38,360 --> 00:02:42,208
那么可能这与价格下跌有关

40
00:02:42,208 --> 00:02:47,036
这些都是一般问题的一个特例

41
00:02:47,036 --> 00:02:52,170
结合文本和时间序列解释话题背后的因果

42
00:02:52,170 --> 00:02:56,020
这里的输入内容就是时间序列加上

43
00:02:56,020 --> 00:03:00,580
同时期的文本数据
就是伴随的文本流

44
00:03:02,400 --> 00:03:06,500
这点与标准的主题模型不同

45
00:03:06,500 --> 00:03:08,740
之前我们只是需要进行文本收集

46
00:03:08,740 --> 00:03:11,960
这就是我们这里时间序列的作用
时间序列用来做背景

47
00:03:13,090 --> 00:03:16,302
我们想要生成的输出是

48
00:03:16,302 --> 00:03:21,270
从信息流找到与时间序列强相关的话题

49
00:03:22,420 --> 00:03:26,410
比如每当话题的出现伴随着价格的下降等等

50
00:03:28,650 --> 00:03:30,890
我们把这些话题称作因果话题

51
00:03:30,890 --> 00:03:35,730
当然它们不是严格意义上的因果关系

52
00:03:35,730 --> 00:03:41,120
我们无法确认它们之间是否有因果关系

53
00:03:41,120 --> 00:03:43,090
也无法确认因果关系的存在

54
00:03:43,090 --> 00:03:47,960
这就是我们把causal打引号的原因

55
00:03:47,960 --> 00:03:51,600
但至少话题之间是相关的

56
00:03:51,600 --> 00:03:53,230
可能能够解释结果

57
00:03:53,230 --> 00:03:58,090
人们自然可以进一步分析这些话题
更好地理解这个问题

58
00:03:59,420 --> 00:04:04,640
输出会像主题建模一样
包含一些话题

59
00:04:04,640 --> 00:04:08,740
但我们希望这些并不是
一般的话题

60
00:04:08,740 --> 00:04:13,450
这些话题不一定是
对数据解释能力最好的

61
00:04:13,450 --> 00:04:17,270
但它们需要能够解释文本中的数据

62
00:04:17,270 --> 00:04:21,477
意味着它们需要指向文本中有意义的话题

63
00:04:21,477 --> 00:04:23,870
更重要的是

64
00:04:23,870 --> 00:04:29,760
它们应该与外在用作背景的时间序列相关

65
00:04:29,760 --> 00:04:33,580
要了解我们如何解决这个问题

66
00:04:33,580 --> 00:04:36,930
首先我们利用反应话题模型来解答
比如潜在概率语义分析(PLSA)

67
00:04:36,930 --> 00:04:40,330
然后我们可以将模型用到文本流上

68
00:04:40,330 --> 00:04:44,260
加上一些拓展内容
比如CPLSA或是说带有背景的潜在概率语义分析(英文似乎有误)

69
00:04:44,260 --> 00:04:49,330
然后我们在相关检验中比较这些话题

70
00:04:49,330 --> 00:04:51,440
了解在时间域话题的覆盖情况

71
00:04:53,260 --> 00:04:59,300
那么最简单的方法
就是从

72
00:04:59,300 --> 00:05:04,000
与时间序列相关性最强的话题集中选择一个

73
00:05:05,230 --> 00:05:08,090
但是这个方法可能不是太好

74
00:05:08,090 --> 00:05:09,050
为什么？
因为你不知道它在血液中的浓度

75
00:05:09,050 --> 00:05:13,150
从图上看
如果用潜在概率语义分析(PLSA)或是隐含狄利克雷分布(LDA)(怀疑英文有误)

76
00:05:13,150 --> 00:05:17,640
可以选择的话题可能十分有限

77
00:05:17,640 --> 00:05:20,905
我们也知道这些模型会最大化文本数据的可能性

78
00:05:20,905 --> 00:05:24,685
那么这些话题能够较好地解释文本

79
00:05:24,685 --> 00:05:28,710
但是这些话题
可能与时间序列并不相关

80
00:05:28,710 --> 00:05:33,660
即使我们挑到其中最好的、最相关的

81
00:05:34,800 --> 00:05:36,170
可能从因果关系讨论也不是很有意义

82
00:05:37,840 --> 00:05:42,740
因此这里有一个更好的方法

83
00:05:42,740 --> 00:05:46,320
这种做法被称为迭代因果主题建模

84
00:05:46,320 --> 00:05:50,815
想法就是在筛选话题时
进行迭代调整

85
00:05:50,815 --> 00:05:56,100
利用加入时间序列的主题模型
生成一个乘积

86
00:05:57,260 --> 00:06:00,590
这里我来展示一下具体怎样做

87
00:06:00,590 --> 00:06:02,630
将文本流作为输入

88
00:06:02,630 --> 00:06:06,140
然后利用一般的主题建模
生成许多话题

89
00:06:06,140 --> 00:06:07,300
比方说四个话题

90
00:06:07,300 --> 00:06:07,810
这是复平面

91
00:06:09,040 --> 00:06:14,540
然后我们利用外部的时间序列

92
00:06:14,540 --> 00:06:19,140
评估哪个话题在因果上相关
或是与时间序列更为相关

93
00:06:19,140 --> 00:06:21,800
那么我们需要将这些话题排个序

94
00:06:21,800 --> 00:06:24,972
我们可能认为话题1和话题4相关性更强

95
00:06:24,972 --> 00:06:26,830
话题2和话题3可能不那么强

96
00:06:26,830 --> 00:06:29,660
我们可以就做到这里

97
00:06:29,660 --> 00:06:33,530
那么就跟之前讲的简单的方法一样

98
00:06:33,530 --> 00:06:38,150
然后我们可以把这些话题作为因果主题

99
00:06:38,150 --> 00:06:41,680
但是我们也可以认为这些话题不是很好

100
00:06:41,680 --> 00:06:45,850
因为这些话题只是解释了整个文本的联系

101
00:06:45,850 --> 00:06:46,700
但是

102
00:06:46,700 --> 00:06:50,180
最好的话题跟我们的时间序列也不相关

103
00:06:51,430 --> 00:06:57,460
这种情形下我们能做的就是
聚焦到单词层面

104
00:06:57,460 --> 00:07:02,830
对每个话题中涉及的词汇进行排序

105
00:07:02,830 --> 00:07:07,810
假设话题1是我们要检验的

106
00:07:07,810 --> 00:07:13,030
我们知道话题1是与时间序列相关的

107
00:07:13,030 --> 00:07:17,390
至少是我们从这组话题中能找到的最好的

108
00:07:18,490 --> 00:07:22,590
然后我们就进一步看话题中的词
频率最高的词

109
00:07:23,810 --> 00:07:26,120
如果话题与时间序列相关

110
00:07:26,120 --> 00:07:30,740
那么其中的一些词一定与时间序列高度相关

111
00:07:30,740 --> 00:07:35,480
比如这里我们可能会看到词1和词3

112
00:07:35,480 --> 00:07:40,630
呈现正相关
而词2和词4则是负相关

113
00:07:41,640 --> 00:07:47,180
因此就话题而言
将具有不同相关关系的词混在一起可能并不合适

114
00:07:47,180 --> 00:07:50,300
那么我们接下来
就把这些词分开

115
00:07:50,300 --> 00:07:54,980
我们用红色的词表示正相关关系

116
00:07:54,980 --> 00:07:55,850
词1和词3
然后

117
00:07:55,850 --> 00:07:58,590
我们也能得到一个子话题

118
00:08:00,890 --> 00:08:02,020
如果你想的话

119
00:08:02,020 --> 00:08:06,930
然后那个表示负相关的词
词2和词4

120
00:08:07,980 --> 00:08:14,040
现在这些子话题
或者说是话题的变化情况

121
00:08:14,040 --> 00:08:20,100
是基于相关性分析得到的结果
它们依然跟原来的话题1十分相关

122
00:08:20,100 --> 00:08:21,950
但是它们已经偏离了目标

123
00:08:21,950 --> 00:08:28,260
因为利用时间序列信息选择是有偏的

124
00:08:28,260 --> 00:08:33,310
某种程度上我们会期望

125
00:08:33,310 --> 00:08:37,860
子话题会比原话题1与时间序列更为相关

126
00:08:37,860 --> 00:08:41,560
因为话题1单词混合在一起
我们就把它们分开

127
00:08:42,650 --> 00:08:45,210
任意一个子话题

128
00:08:46,210 --> 00:08:49,690
都应该与时间序列的趋势更为一致

129
00:08:49,690 --> 00:08:52,930
然而可能并没有我们提的那么一致

130
00:08:52,930 --> 00:08:57,760
这里的想法是回到主题模型

131
00:08:57,760 --> 00:09:02,370
利用得到的话题指导主题建模

132
00:09:02,370 --> 00:09:06,140
话句话说
我们要用主题模型寻找

133
00:09:06,140 --> 00:09:10,080
与两个子话题相似的话题

134
00:09:10,080 --> 00:09:17,110
这就会让话题与时间序列更为相关

135
00:09:17,110 --> 00:09:21,660
当然我们可以用话题模型再生成一些话题

136
00:09:21,660 --> 00:09:25,772
可以进一步从时间序列出发

137
00:09:25,772 --> 00:09:27,227
寻找高度相关的话题

138
00:09:27,227 --> 00:09:32,180
然后我们分析话题中的词汇构成

139
00:09:32,180 --> 00:09:35,380
分析词汇层次的相关性

140
00:09:35,380 --> 00:09:39,840
然后得到的更为相关的子话题就可以

141
00:09:39,840 --> 00:09:44,420
再一次用到寻找话题的模型当中

142
00:09:46,000 --> 00:09:50,460
因此整个过程就是自发最优化因果关系

143
00:09:50,460 --> 00:09:52,840
和一致性，这是我们的最终目标

144
00:09:52,840 --> 00:09:53,880
对吧

145
00:09:53,880 --> 00:09:58,550
这里你能看到纯主题模型在最大化话题一致性上做的很好

146
00:09:58,550 --> 00:10:01,980
话题就会很有意义

147
00:10:02,990 --> 00:10:07,125
如果我们只做因果检验
或是相关性检验

148
00:10:07,125 --> 00:10:12,150
我们能得到一组与时间序列强相关的词

149
00:10:12,150 --> 00:10:14,770
但是它们可能什么意义都没有

150
00:10:14,770 --> 00:10:17,820
可能这种联系并不是本质上的

151
00:10:17,820 --> 00:10:20,330
所以这就是另一个极端
在顶部

152
00:10:21,490 --> 00:10:25,430
理想的情况是找到具备因果性的话题

153
00:10:25,430 --> 00:10:29,470
在话题一致性和因果关系都能表现好

154
00:10:29,470 --> 00:10:30,180
在这种方法中

155
00:10:30,180 --> 00:10:35,690
它可以被看作是最大化这两个必要指标的一个替代方式

156
00:10:35,690 --> 00:10:40,210
当我们使用主题模型的时候
我们最大化一致性

157
00:10:40,210 --> 00:10:44,200
但当我们将主题模型涉及的词分解

158
00:10:44,200 --> 00:10:47,760
组成词集之后
就与时间序列强相关

159
00:10:47,760 --> 00:10:51,230
我们选择其中与时间序列相关性最强的词

160
00:10:51,230 --> 00:10:54,830
我们又将模型推回到因果层面

161
00:10:54,830 --> 00:10:58,820
提高在因果层面的得分

162
00:10:58,820 --> 00:11:04,020
之后我们将选择的词作为起点

163
00:11:04,020 --> 00:11:08,690
估计主题模型
我们又回到了一致性优化的道路上

164
00:11:08,690 --> 00:11:13,199
通过主题模型我们可以确保
新生成的话题会是一致的

165
00:11:13,199 --> 00:11:17,461
我们可以像图中这样重复进行最优化

166
00:11:20,520 --> 00:11:25,445
我想你们唯一你们还没见过的部分就是如何

167
00:11:25,445 --> 00:11:27,380
衡量因果关系

168
00:11:27,380 --> 00:11:30,660
因为这部分正要开始讲

169
00:11:30,660 --> 00:11:33,050
我们就来讨论一下这个问题

170
00:11:33,050 --> 00:11:34,050
这里我们看到

171
00:11:34,050 --> 00:11:36,640
假设我们有一个关于政府回应的话题

172
00:11:36,640 --> 00:11:40,780
我们想了解话题覆盖内容随时间变化的情况

173
00:11:40,780 --> 00:11:42,240
因此我们有一个时间序列X下标t

174
00:11:43,380 --> 00:11:48,270
我们还有一个表示外部信息的时间序列

175
00:11:48,270 --> 00:11:50,735
这是一个非文本时间序列Y下标t

176
00:11:50,735 --> 00:11:52,783
这是股价的数据

177
00:11:52,783 --> 00:11:57,560
现在问题是Xt是不是Yt变化的原因？

178
00:11:58,680 --> 00:12:03,560
换句话说我们想要找到
两者之间的因果关系

179
00:12:03,560 --> 00:12:07,210
或许只是两者的相关程度

180
00:12:08,360 --> 00:12:11,840
在这个框架下我们有许多办法

181
00:12:11,840 --> 00:12:14,480
比如进行成对相关性检验
就是一种常用的方法

182
00:12:14,480 --> 00:12:17,340
现在我们要考虑时间滞后的因素

183
00:12:17,340 --> 00:12:19,800
才能了解因果关系的情况

184
00:12:19,800 --> 00:12:25,410
利用某些过去的数据
然后利用过去数据

185
00:12:26,790 --> 00:12:30,990
与表示未来的y的数据点进行相关性回归

186
00:12:30,990 --> 00:12:36,010
比如说

187
00:12:36,010 --> 00:12:41,240
借助滞后项的引入我们希望能
检验到一些因果关系

188
00:12:41,240 --> 00:12:44,030
甚至是利用相关关系的变量
比如皮尔逊相关系数

189
00:12:45,060 --> 00:12:50,850
但是通常来讲
检验因果应该使用格兰杰因果检验

190
00:12:52,500 --> 00:12:55,040
想法很简单

191
00:12:55,040 --> 00:12:58,710
基本来说就是将Y的历史信息放入回归模型

192
00:12:58,710 --> 00:13:03,000
预测Y本身

193
00:13:03,000 --> 00:13:06,200
这是在没有其他信息的情况下的最好结果了

194
00:13:06,200 --> 00:13:08,470
我们要建立这样一个模型

195
00:13:08,470 --> 00:13:12,830
然后我们加入一些
X的历史信息到模型中

196
00:13:12,830 --> 00:13:16,340
看看是否能够改进Y的预测

197
00:13:16,340 --> 00:13:21,170
如果我们能够得到统计显著的区别

198
00:13:21,170 --> 00:13:25,700
那么我们就说X与Y之间
有一定的因果关系

199
00:13:25,700 --> 00:13:30,570
否则就不会对Y的预测有因果上的改进

200
00:13:32,080 --> 00:13:35,670
换句话说
如果结果不显著

201
00:13:35,670 --> 00:13:39,150
那么就意味着X与Y之间没有因果关系

202
00:13:39,150 --> 00:13:40,910
这是基本思路

203
00:13:40,910 --> 00:13:45,310
现在我们没时间详细解释

204
00:13:45,310 --> 00:13:49,370
但是你可以从参考文献进行更多了解

205
00:13:49,370 --> 00:13:52,460
这是一个非常方便的措施

206
00:13:52,460 --> 00:13:53,850
有许多应用

207
00:13:55,790 --> 00:14:00,440
接下来我们看一些用这个方法得到的结果

208
00:14:00,440 --> 00:14:02,420
数据是纽约时报

209
00:14:02,420 --> 00:14:06,110
2000年6月到2011年12月的情况

210
00:14:06,110 --> 00:14:12,960
这里我们使用的时间序列是
两个公司的股价

211
00:14:12,960 --> 00:14:15,040
美国航空公司和苹果

212
00:14:15,040 --> 00:14:21,230
目的是看如果利用组合的时间序列数据

213
00:14:21,230 --> 00:14:26,580
我们能否得到一些与时间序列相关的主题

214
00:14:26,580 --> 00:14:29,890
假设我们没有输入
也不用背景

215
00:14:29,890 --> 00:14:35,330
那么纽约时报的话题经过PLSA方法

216
00:14:35,330 --> 00:14:38,250
得到的就是人们新闻中谈论的一般话题

217
00:14:38,250 --> 00:14:40,560
没错
就是新闻事件中的主要话题

218
00:14:41,820 --> 00:14:47,860
现在你可以看到这些话题与时间序列是有偏离的

219
00:14:47,860 --> 00:14:51,030
尤其是看这里下划线的单词

220
00:14:51,030 --> 00:14:54,280
在美国航空公司的结果中
你可以看到航空公司、

221
00:14:54,280 --> 00:14:59,090
机场、高空、联合贸易、恐怖主义等等

222
00:14:59,090 --> 00:15:05,580
这就是与外部时间序列相关的话题

223
00:15:05,580 --> 00:15:06,370
在右侧，

224
00:15:06,370 --> 00:15:11,540
你看到其中一些话题明显与苹果相关
对

225
00:15:11,540 --> 00:15:17,110
比如电脑、技术、软件、互联网、com、网络等等

226
00:15:17,110 --> 00:15:19,880
这就是说时间序列

227
00:15:19,880 --> 00:15:24,410
可能成为背景
偏离寻找的话题

228
00:15:24,410 --> 00:15:25,890
从另一个角度来看

229
00:15:25,890 --> 00:15:30,782
这些结果让我们了解人们在每种情况下都在谈论什么

230
00:15:30,782 --> 00:15:36,200
所以不仅是人
不仅是人们说的内容

231
00:15:36,200 --> 00:15:41,130
还有那些可能与股价相关的话题

232
00:15:41,130 --> 00:15:43,690
这里的话题可以作为一个起点

233
00:15:43,690 --> 00:15:48,320
进一步研究这个问题
寻找真正的因果关系

234
00:15:48,320 --> 00:15:54,136
这里是其他的一些结果

235
00:15:54,136 --> 00:15:58,980
是关于总统选举的时间序列的

236
00:15:58,980 --> 00:16:02,760
这些数据来自爱荷华州的电子市场

237
00:16:02,760 --> 00:16:04,770
这是一个预测市场

238
00:16:04,770 --> 00:16:06,000
数据是一样的

239
00:16:06,000 --> 00:16:09,540
纽约时报从2000年5月到2000年10月

240
00:16:09,540 --> 00:16:13,108
是关于2000年的总统竞选选举

241
00:16:13,108 --> 00:16:16,730
你可以看到

242
00:16:16,730 --> 00:16:20,389
这些是纽约时报里最显著的三个话题

243
00:16:21,680 --> 00:16:26,520
如果你看这些话题
它们的确与竞选有关

244
00:16:26,520 --> 00:16:30,920
实际上这些议题

245
00:16:30,920 --> 00:16:35,710
与总统选举的重要议题十分相关

246
00:16:35,710 --> 00:16:40,260
这里我要指出
文本数据已经进行了筛选

247
00:16:40,260 --> 00:16:43,070
选取了提到竞选人名字的文章

248
00:16:45,760 --> 00:16:50,110
这是这些新闻的一个子集

249
00:16:50,110 --> 00:16:51,890
与之前的实验很不一样

250
00:16:53,110 --> 00:16:58,230
这里的结果可以说明
利用这种方法可以发现

251
00:16:58,230 --> 00:17:02,200
总统选举中的一些重要议题

252
00:17:02,200 --> 00:17:07,650
比如减税、原油能源、堕胎和强制管制都是

253
00:17:07,650 --> 00:17:11,730
总统选举中收到关注的重要议题

254
00:17:11,730 --> 00:17:16,230
一些政治学的文章也可以支持这个观点

255
00:17:17,250 --> 00:17:21,960
我也讨论了维基百科

256
00:17:21,960 --> 00:17:26,750
因此结果基本上表明
该方法可以有效

257
00:17:26,750 --> 00:17:31,545
发现可能的因果话题
建立在时间序列数据之上

258
00:17:35,330 --> 00:17:37,720
这里有连篇推荐阅读

259
00:17:37,720 --> 00:17:44,810
一篇是关于给予时间序列反馈的迭代主题建模

260
00:17:44,810 --> 00:17:48,380
你可以了解这一方法应用的更多细节

261
00:17:48,380 --> 00:17:52,965
第二篇是关于格兰杰因果检验

262
00:17:55,730 --> 00:18:02,553
最后我们来总结一下基于文本预测的内容

263
00:18:02,553 --> 00:18:06,420
现在基于文本的预测

264
00:18:06,420 --> 00:18:09,070
针对包含文本的大数据十分有用

265
00:18:09,070 --> 00:18:13,340
因为他们能够帮助我们了解世界上出现的新知识

266
00:18:13,340 --> 00:18:16,250
这些知识可能超出我们文本中的讨论

267
00:18:17,520 --> 00:18:23,950
进而辅助优化我们的决断

268
00:18:23,950 --> 00:18:25,609
它有了更为广泛的应用

269
00:18:28,090 --> 00:18:31,670
在预测中文本数据常与非文本数据结合使用

270
00:18:31,670 --> 00:18:34,190
因为出于预测的需要

271
00:18:34,190 --> 00:18:37,940
我们希望将非文本数据和文本数据结合考虑

272
00:18:37,940 --> 00:18:41,740
预测越精确越好

273
00:18:41,740 --> 00:18:44,525
因此对于文本和非文本的分析

274
00:18:44,525 --> 00:18:49,550
十分必要也十分有用

275
00:18:49,550 --> 00:18:53,150
当我们将文本和非文本结合起来的时候

276
00:18:53,150 --> 00:18:56,218
我们可以看到两者互相优化

277
00:18:56,218 --> 00:19:00,650
非文本数据为文本挖掘提供了背景

278
00:19:00,650 --> 00:19:04,410
我们已经讨论了许多背景文本挖掘的技术

279
00:19:04,410 --> 00:19:08,080
另一方面，文本数据也

280
00:19:08,080 --> 00:19:12,500
协助解释非文本数据的样式
我们把这叫做样式注解

281
00:19:14,680 --> 00:19:17,660
总的来讲，这是一个十分活跃的研究领域

282
00:19:17,660 --> 00:19:20,100
有许多新发表的文章

283
00:19:20,100 --> 00:19:25,211
也有许多挑战亟待解决

284
00:19:25,211 --> 00:19:35,211
[音乐]