1
00:00:00,098 --> 00:00:07,347
[SOUND]
Hi, in this session

2
00:00:07,347 --> 00:00:13,220
we are going to give a brief overview
on clustering different types of data.

3
00:00:13,220 --> 00:00:17,430
We encounter various
kinds of types of data.

4
00:00:17,430 --> 00:00:18,433
For example,

5
00:00:18,433 --> 00:00:24,208
the early clustering algorithm most times
with the design was on numerical data.

6
00:00:24,208 --> 00:00:29,445
And the second type of data is category
data, including the binary that

7
00:00:29,445 --> 00:00:35,130
most people consider as also can be
handled in categorical data or category.

8
00:00:35,130 --> 00:00:39,365
For example, gender, race, zip code, or

9
00:00:39,365 --> 00:00:44,270
market-basket data,
you would consider the data is discrete.

10
00:00:44,270 --> 00:00:51,300
There's no natural order, but
certain kind of data is text data,

11
00:00:51,300 --> 00:00:57,640
this is very popular in social media,
on the Web, or social networks.

12
00:00:59,540 --> 00:01:03,720
Usually if we consider
a word as one dimension,

13
00:01:03,720 --> 00:01:09,470
then we are handling very high dimensional
data, but they are very sparse.

14
00:01:09,470 --> 00:01:12,240
Their value usually corresponding
to word frequencies.

15
00:01:13,490 --> 00:01:18,205
The methods to handle such data,
include a combination of k-means and

16
00:01:18,205 --> 00:01:23,880
agglomarative method, topical modelling
methods, or co-clustering methods.

17
00:01:23,880 --> 00:01:26,365
We are going to discuss
this extensive later.

18
00:01:26,365 --> 00:01:31,653
Multimedia data is another
kind of data needs clustering.

19
00:01:31,653 --> 00:01:33,730
Usually images, audio, video,

20
00:01:33,730 --> 00:01:38,960
those are Flickr and
YouTube actually are multimedia data.

21
00:01:38,960 --> 00:01:41,420
They are multi-modal in a sense.

22
00:01:41,420 --> 00:01:46,170
They have image, audio, video, many cases
they have text, as captions as well.

23
00:01:47,330 --> 00:01:52,280
We can consider data are contextual data,
they contain both behavioral and

24
00:01:52,280 --> 00:01:54,600
the contextual attributes.

25
00:01:54,600 --> 00:01:59,016
For example for images,
we can consider the position of a pixel

26
00:01:59,016 --> 00:02:04,240
represents its context,
the value represents its behavior.

27
00:02:04,240 --> 00:02:06,360
For video and music data,

28
00:02:06,360 --> 00:02:10,945
we can consider temporal ordering of
the records represents its meaning.

29
00:02:10,945 --> 00:02:15,890
Time-series data is another
popularly encountered data

30
00:02:15,890 --> 00:02:20,780
like in sensors, stock markets,
temporal tracking, or

31
00:02:20,780 --> 00:02:25,090
forecasting, those task
are usually handled time-series.

32
00:02:25,090 --> 00:02:29,200
Time-series, we usually consider
data are temporally dependent.

33
00:02:30,280 --> 00:02:34,510
They are consecutive,
usually the interval is somehow equal.

34
00:02:35,930 --> 00:02:41,100
Like, we can consider time
as contextual attributes,

35
00:02:41,100 --> 00:02:43,770
data value as behavioral attribute.

36
00:02:45,590 --> 00:02:50,750
Usually such analysis include
correlation-based online analysis,

37
00:02:50,750 --> 00:02:54,800
like online clustering of
stocks to find stock tickers.

38
00:02:56,050 --> 00:03:00,460
Or we use shape-based offline analysis,
for example,

39
00:03:00,460 --> 00:03:04,539
we can cluster ECG based
on overall shapes.

40
00:03:05,750 --> 00:03:08,380
Sequence data is another kind of data.

41
00:03:08,380 --> 00:03:14,234
Usually in weblog analysis,
or biological sequence

42
00:03:14,234 --> 00:03:19,183
analysis, or analyze the system commands.

43
00:03:19,183 --> 00:03:24,870
These, we can think the placement rather
than time, the contextual attribute.

44
00:03:24,870 --> 00:03:25,950
That means where they are.

45
00:03:27,190 --> 00:03:31,990
Then the similarity function,
include Hamming distance, edit distance,

46
00:03:31,990 --> 00:03:35,050
longest common subsequences.

47
00:03:35,050 --> 00:03:39,100
The clustering method, we call sequence
clustering may use suffix tree,

48
00:03:39,100 --> 00:03:42,120
may use generative model,
like Hidden Markov Model.

49
00:03:43,910 --> 00:03:46,540
Stream data is another kind of data.

50
00:03:46,540 --> 00:03:50,560
Stream data can be considered
as a real-time data,

51
00:03:50,560 --> 00:03:53,160
like water flowing in and out.

52
00:03:53,160 --> 00:03:55,470
It may evolve a long time.

53
00:03:55,470 --> 00:04:00,450
It may have concept shifts
because stream coming and go.

54
00:04:00,450 --> 00:04:06,559
So, we need a single pass algorithm,
rather you can see it again and again.

55
00:04:08,110 --> 00:04:13,130
And the typical method for stream
clustering could be micro-clustering,

56
00:04:13,130 --> 00:04:18,010
that means we need to create efficient
intermediate representation by some

57
00:04:18,010 --> 00:04:22,570
kind of a micro-clustering method.

58
00:04:22,570 --> 00:04:27,730
Graphs and homogeneous networks
is another kind of data.

59
00:04:27,730 --> 00:04:29,735
This then kind of data usually,

60
00:04:29,735 --> 00:04:35,060
so-called homogeneous networks that
means we consider networks as graphs,

61
00:04:35,060 --> 00:04:40,430
the nodes and
edges actually are of one kind, one type.

62
00:04:40,430 --> 00:04:45,890
Actually any kind of data
can be modeled as a graph

63
00:04:47,010 --> 00:04:51,800
with the nodes as different attributes and

64
00:04:51,800 --> 00:04:56,100
entries, and
edge graph in their similarity values.

65
00:04:57,520 --> 00:05:02,670
The typical method for handling graph
clustering could be generative models,

66
00:05:02,670 --> 00:05:06,615
combinatorial algorithm like graph cuts,
spectral clustering method,

67
00:05:06,615 --> 00:05:09,549
non-negative matrix factorization methods.

68
00:05:11,460 --> 00:05:17,070
Then a little bit beyond homogeneous
network are heterogeneous networks.

69
00:05:17,070 --> 00:05:23,208
This kind of network consists of
multiple types of nodes and edges.

70
00:05:23,208 --> 00:05:30,447
Like a bibliographical data, hospital,
handling disease, patients, doctors, and

71
00:05:30,447 --> 00:05:36,056
treatments to cluster different
kinds of nodes and links together.

72
00:05:36,056 --> 00:05:38,980
There are some interesting algorithms,
like the NetClus algorithm.

73
00:05:41,250 --> 00:05:45,610
Uncertain data,
means the data may contain noise,

74
00:05:45,610 --> 00:05:50,040
may have approximate values,
or multiple possible values.

75
00:05:50,040 --> 00:05:55,110
Usually we need to incorporate
some probabilistic information,

76
00:05:55,110 --> 00:05:56,920
like distribution, or

77
00:05:56,920 --> 00:06:01,996
approximate values that were
improve the quality of clustering.

78
00:06:01,996 --> 00:06:07,410
Finally, recently,
there are lots of discussion on big data.

79
00:06:07,410 --> 00:06:10,050
That means, we can model systems.

80
00:06:10,050 --> 00:06:15,588
That may store and process very big data,
like weblog analysis.

81
00:06:15,588 --> 00:06:20,154
Usually, like Google's MapReduce
framework is you have Map

82
00:06:20,154 --> 00:06:24,908
function to distribute
the computation across many machines.

83
00:06:24,908 --> 00:06:31,118
Then we have Reduce function to aggregate
the results obtained from the Map step.

84
00:06:31,118 --> 00:06:36,145
So we can see, the data is very
rich that's why the clustering

85
00:06:36,145 --> 00:06:43,216
is a rather sophisticated methodologies,
trying to handle different kinds of data.

86
00:06:43,216 --> 00:06:53,216
[MUSIC]