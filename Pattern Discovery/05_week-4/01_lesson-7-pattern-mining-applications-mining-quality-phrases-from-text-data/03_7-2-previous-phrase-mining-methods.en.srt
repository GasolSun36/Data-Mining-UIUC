1
00:00:01,230 --> 00:00:05,894
Now, we first introduced a few
previous phrase mining methods.

2
00:00:05,894 --> 00:00:12,930
Phrase mining actually
originally came from

3
00:00:14,030 --> 00:00:19,659
the natural language processing community
called chunking or noun phrase chunking.

4
00:00:21,390 --> 00:00:27,570
Essentially is a remodel of phrase
as a sequence of labeling problem.

5
00:00:27,570 --> 00:00:33,250
For example, you can squeeze a label word
at the beginning of this noun phrase,

6
00:00:33,250 --> 00:00:37,440
then you see another word that could
be inside of noun phrases, and

7
00:00:37,440 --> 00:00:40,380
you may have something
outside of this phrase.

8
00:00:42,170 --> 00:00:46,180
This will need a lot of annotation and
a training effort.

9
00:00:47,220 --> 00:00:50,580
For example, you may ask domain experts

10
00:00:50,580 --> 00:00:54,840
to annotate hundreds of
documents as training data.

11
00:00:54,840 --> 00:01:01,043
Then we can use the software, use
the measures to train a supervised model

12
00:01:01,043 --> 00:01:06,760
based on part-of-speech features
like part of speech tracking.

13
00:01:06,760 --> 00:01:12,588
Okay, the recent trend is
also try to use web n-grams.

14
00:01:12,588 --> 00:01:15,683
Those web n-grams,we can
get some statistics,

15
00:01:15,683 --> 00:01:20,558
we'll be able to use this distributional
features to generate good phrases.

16
00:01:20,558 --> 00:01:25,483
This one was found by Bergsma and
others in 2010.

17
00:01:25,483 --> 00:01:30,670
The state-of-the-art
performance using this approach

18
00:01:30,670 --> 00:01:36,700
is about 95% accuracy and
about 88% phrase-level F-score.

19
00:01:36,700 --> 00:01:42,189
However, this method suffers
from the high annotation cost.

20
00:01:43,190 --> 00:01:47,818
And then it will not be scalable
to a new language for example,

21
00:01:47,818 --> 00:01:53,069
new labor English, it may not be used for
French or a new domain like you

22
00:01:53,069 --> 00:01:58,866
labor the news may not be able to use for
computer science or new genre, okay?

23
00:01:58,866 --> 00:02:05,237
So it may not fit domain-specific,
dynamic, emerging applications.

24
00:02:05,237 --> 00:02:10,652
For example, there are lots of new
articles in scientific domain,

25
00:02:10,652 --> 00:02:14,750
computer science domain or
like medical domains.

26
00:02:14,750 --> 00:02:19,790
Or the machine may generate
a lot of query logs.

27
00:02:19,790 --> 00:02:22,589
Our social media may contain Yelp and
Twitter data.

28
00:02:23,610 --> 00:02:29,160
This kind of data set is so
domain specific and dynamic,

29
00:02:29,160 --> 00:02:36,030
so it's hard to assign or change every
subset of such data using annotation.

30
00:02:37,410 --> 00:02:41,559
So people want to develop
unsupervised phrase mining method.

31
00:02:42,840 --> 00:02:48,290
Actually, many unsupervised
phrase mining studies are close

32
00:02:48,290 --> 00:02:49,960
linked to as topic modeling.

33
00:02:51,380 --> 00:02:56,214
Topic modeling essentially is
a new recent developed method.

34
00:02:56,214 --> 00:03:03,228
Represent topics by many,
many phrase words.

35
00:03:03,228 --> 00:03:08,315
You get every topic is written by
a word distribution, and documents

36
00:03:08,315 --> 00:03:14,380
a set of documents actually may contain
many topics with different proportions.

37
00:03:16,230 --> 00:03:22,950
This method does not require any prior
annotations or labeling of the documents.

38
00:03:22,950 --> 00:03:27,236
It relies on statistical
topic modeling algorithm.

39
00:03:27,236 --> 00:03:33,630
One of the most popular ones, LDA, or
we call Latent Dirichlet Allocation

40
00:03:33,630 --> 00:03:37,801
developed by David Blei and
others in 2003.

41
00:03:37,801 --> 00:03:42,661
Actually to do phrase mining using
topic modelling there are three

42
00:03:42,661 --> 00:03:45,140
different methods.

43
00:03:45,140 --> 00:03:50,270
One is we simultaneously
infer the topics and

44
00:03:50,270 --> 00:03:55,530
the tokens, the phrases at the same time
using some kind of generative model.

45
00:03:57,240 --> 00:04:02,370
The second method is first
using generative model to

46
00:04:02,370 --> 00:04:08,040
generate topic models and
using topic model, try to group

47
00:04:08,040 --> 00:04:14,076
different words into n-grams,
into phrases to visualize such topics.

48
00:04:14,076 --> 00:04:19,200
The third one, the newest developed
one is first we phrases mining

49
00:04:19,200 --> 00:04:21,630
before we do topic model.

50
00:04:21,630 --> 00:04:26,170
That means, we mine phrases and
impose such phrases

51
00:04:26,170 --> 00:04:31,020
on the bag-of-words modelling process.

52
00:04:31,020 --> 00:04:34,580
So let's look at the first method.

53
00:04:34,580 --> 00:04:39,869
We call strategy 1 is simultaneously
inferring phrases and topics.

54
00:04:41,160 --> 00:04:48,450
There studies the first one in 2006
was called bigram topic model.

55
00:04:48,450 --> 00:04:52,840
That means we use some kind of
probabilistic generating model

56
00:04:52,840 --> 00:04:57,910
to look at the previous words in
the topic to see whether the next word

57
00:04:57,910 --> 00:05:00,459
should belong to the same
topic should be a phrase.

58
00:05:02,100 --> 00:05:08,566
And it's generalization from this
Bigram Topic Model is TNG or

59
00:05:08,566 --> 00:05:11,984
called Topical N-Grams model.

60
00:05:11,984 --> 00:05:14,313
It was developed in 2007.

61
00:05:14,313 --> 00:05:17,130
It is a probabilistic model.

62
00:05:17,130 --> 00:05:19,230
Generates words in textual order,

63
00:05:19,230 --> 00:05:23,970
then create n-grams by
concatenating successive bigrams.

64
00:05:25,430 --> 00:05:30,295
Then the source that is by Lindsey and
others into some twelve

65
00:05:30,295 --> 00:05:35,870
called PDLDA or Phrase-Discovering LDA.

66
00:05:35,870 --> 00:05:41,386
For this measure, we first view each
sentence as a time-series of words.

67
00:05:41,386 --> 00:05:46,510
Then using PDLDA, and

68
00:05:46,510 --> 00:05:52,860
assume that generative parameter like
those topic may change periodically, then

69
00:05:52,860 --> 00:05:59,370
each word is drawn based on the previous
m words, based on the previous context.

70
00:05:59,370 --> 00:06:01,850
And the current phrase topic, so

71
00:06:01,850 --> 00:06:05,120
we can generate whether this
word should be there or not.

72
00:06:05,120 --> 00:06:13,750
Okay, this method, due to its high model
complexity, it tends to overfitting.

73
00:06:13,750 --> 00:06:17,570
That means it overfitting
to a particular topic.

74
00:06:17,570 --> 00:06:21,860
Sometimes it may not generate
very good quality phrases.

75
00:06:21,860 --> 00:06:26,630
Another why it has high inference cost,

76
00:06:26,630 --> 00:06:30,960
because of this complex generative
process, it runs pretty slow.

77
00:06:32,770 --> 00:06:38,262
The second strategy is post
topic-modelling phrase construction.

78
00:06:38,262 --> 00:06:43,580
That means refers topic modeling,
then we do phrase construction.

79
00:06:43,580 --> 00:06:47,500
The first that work called TurboTopics.

80
00:06:47,500 --> 00:06:53,862
TurboTopics was developed in 2009
by David Blei and John Lafferty.

81
00:06:53,862 --> 00:07:00,964
The general idea is first to Latent
Dirichlet Allocation to do topic modeling,

82
00:07:00,964 --> 00:07:08,078
then based on topic modeling we do
post-processing to construct the phrases.

83
00:07:08,078 --> 00:07:15,970
Okay, that means we first perform LDA on
corpus to assign each token a topic model.

84
00:07:15,970 --> 00:07:17,870
This is topic modelling.

85
00:07:17,870 --> 00:07:22,615
Then, we'll merge adjacent unigrams
with the same topic model by

86
00:07:22,615 --> 00:07:28,760
a distribution-free permutation test
on arbitrary-length back-off model.

87
00:07:28,760 --> 00:07:30,310
For example, you can see this.

88
00:07:31,550 --> 00:07:34,670
If you see phase, transition, and

89
00:07:34,670 --> 00:07:40,510
you see phase transition
are in same topic number 11.

90
00:07:40,510 --> 00:07:46,160
And they are consecutive,
likely they could form a phrase.

91
00:07:46,160 --> 00:07:50,590
You can recursively merging
generating such phrases.

92
00:07:50,590 --> 00:07:56,260
We will end recursive merging when all
significant adjacent unigrams have been

93
00:07:56,260 --> 00:08:01,360
merged, so then you will be able
to generate some good phrases.

94
00:08:02,830 --> 00:08:06,460
Another method called KERT is also

95
00:08:06,460 --> 00:08:10,610
first do topic modelling
them do phrase construction.

96
00:08:10,610 --> 00:08:16,233
It was developed by Marina Danilevsky and

97
00:08:16,233 --> 00:08:19,130
others in 2014.

98
00:08:19,130 --> 00:08:23,022
It take first do some LDA, and

99
00:08:23,022 --> 00:08:30,041
then to post-processing for
phrase construction.

100
00:08:30,041 --> 00:08:36,376
The first one the same is turbo topics,
then the interesting thing is it performs

101
00:08:36,376 --> 00:08:43,060
frequent pattern mining to extract
candidate phrases within each topic.

102
00:08:43,060 --> 00:08:48,100
Then perform phrase ranking,
based on four different criteria.

103
00:08:48,100 --> 00:08:50,820
One criteria called popularity.

104
00:08:50,820 --> 00:08:55,940
For example, if you see information
retrieval is more popular,

105
00:08:55,940 --> 00:09:01,620
then cross-language information retrieval,
then information retrieval as a phrase

106
00:09:01,620 --> 00:09:07,320
will rank higher than the cross-language
information retrieval.

107
00:09:07,320 --> 00:09:10,790
The second criteria is concordance.

108
00:09:10,790 --> 00:09:17,130
For example, if you see strong tea quite
often rather you see powerful tea,

109
00:09:17,130 --> 00:09:20,950
or you see active learning quite often
rather than you see learning and

110
00:09:20,950 --> 00:09:25,900
the classification getting together
as a sequence, then we will

111
00:09:25,900 --> 00:09:30,600
say strong tea and
active learning is higher concordance.

112
00:09:32,050 --> 00:09:37,400
The third one for informativeness
essentially is, whether the phrase

113
00:09:37,400 --> 00:09:43,800
generator is more informative, it contains
retrieved information, discriminative.

114
00:09:43,800 --> 00:09:48,100
For example, if you see this paper,
it's almost every research paper,

115
00:09:48,100 --> 00:09:53,060
they have a lot of this paper, so
this paper is more like a stock

116
00:09:53,060 --> 00:09:57,270
words here is more like a stock
phras,e it is not informative.

117
00:09:57,270 --> 00:09:59,690
It rank low, like it should be removed.

118
00:10:00,810 --> 00:10:03,860
The first criteria is completeness.

119
00:10:03,860 --> 00:10:06,060
For example, you see vector machine,

120
00:10:06,060 --> 00:10:11,090
almost every time you see this phrase,
you'll also see support vector machine.

121
00:10:11,090 --> 00:10:13,620
That means vector machine
may not be complete,

122
00:10:13,620 --> 00:10:16,740
and support vector machine
is a complete phase.

123
00:10:18,570 --> 00:10:24,000
Then not only you can compare
phrase quality with the same lens,

124
00:10:24,000 --> 00:10:29,580
in many cases you can compare
phrase quality of mixed lens.

125
00:10:29,580 --> 00:10:34,090
That means you compare vector
machine vs support vector machine.

126
00:10:34,090 --> 00:10:38,340
Rather than using the same lens,
you compare them.

127
00:10:38,340 --> 00:10:43,305
With this process, frequent pattern
mining plus phrase ranking,

128
00:10:43,305 --> 00:10:46,885
this message generate
better quality phrases.