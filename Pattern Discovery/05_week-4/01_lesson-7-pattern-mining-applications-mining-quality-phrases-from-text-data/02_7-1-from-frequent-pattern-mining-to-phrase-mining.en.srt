1
00:00:01,948 --> 00:00:07,110
Now we are going to discuss another
interesting pattern mining applications

2
00:00:07,110 --> 00:00:10,900
called Mining Quality Phrases
from Text Data.

3
00:00:12,640 --> 00:00:16,580
We encounter massive
unstructured text data.

4
00:00:16,580 --> 00:00:24,520
To get knowledge out of text data, a very
important thing is mining quality phrases.

5
00:00:24,520 --> 00:00:31,740
We will discuss how we do it from mining
frequent patterns to mining phrases.

6
00:00:31,740 --> 00:00:37,090
We'll reintroduce some previous
phrase pattern mining methods, then

7
00:00:37,090 --> 00:00:43,140
we are going to discuss two interesting
new algorithms developed by those.

8
00:00:43,140 --> 00:00:48,080
Many of my students,
they are ToPMine and SegPhrase.

9
00:00:49,180 --> 00:00:54,210
ToPMine is mining phrases
without training data, and

10
00:00:54,210 --> 00:00:59,730
SegPhrases by introducing
tiny training data sets

11
00:00:59,730 --> 00:01:03,280
you can further enhance
the phrase mining quality.

12
00:01:04,870 --> 00:01:12,200
Let's first study why we want to get from
frequent pattern mining to phrase mining.

13
00:01:13,690 --> 00:01:17,610
The first question you may ask is
why we want to do phrase mining.

14
00:01:18,940 --> 00:01:25,380
Actually, if we think every word
is a unigram, and then phrases

15
00:01:25,380 --> 00:01:30,960
actually are a set of consecutive words
made from some meaningful semantic unit.

16
00:01:32,240 --> 00:01:39,280
We probably can see, for single words, or
we call unigrams, they're often ambiguous.

17
00:01:39,280 --> 00:01:43,810
For example, when you say united,
people often do not know

18
00:01:43,810 --> 00:01:48,674
you mean United States or
United Airlines or United Parcel Service?

19
00:01:48,674 --> 00:01:56,030
However, once you present them
as a phrase like United States,

20
00:01:56,030 --> 00:02:00,570
or United Airlines,
these kind of phrases are actually

21
00:02:00,570 --> 00:02:05,370
natural meaningful and
unambiguous semantic units.

22
00:02:06,660 --> 00:02:12,970
That means if we want automatically
transform text data to some meaningful

23
00:02:14,210 --> 00:02:18,730
sentences or
to some meaningful analysis structures,

24
00:02:18,730 --> 00:02:23,900
the first important thing is mining
semantically meaningful phrases?

25
00:02:23,900 --> 00:02:28,230
This would transform
text data analysis from

26
00:02:28,230 --> 00:02:30,540
word granularity to phrase granularity.

27
00:02:31,870 --> 00:02:37,230
This will enhance the power and efficiency
and manipulating unstructured data.

28
00:02:38,860 --> 00:02:43,450
However why we want to start
with frequent pattern mining?

29
00:02:43,450 --> 00:02:49,902
The general principle is we want to
explore information redundancy and

30
00:02:49,902 --> 00:02:54,870
use data-driven criteria to
determine phrase boundaries and

31
00:02:54,870 --> 00:02:59,720
the salience instead of using laws
of curation and training data set.

32
00:03:01,110 --> 00:03:06,170
The general methodology is
to explore three ideas.

33
00:03:06,170 --> 00:03:10,200
One is frequent pattern mining and
a colocation analysis.

34
00:03:10,200 --> 00:03:18,285
The second one is explore phrasal
segmentation in documents.

35
00:03:18,285 --> 00:03:24,150
The third one is we will have some
quality phrase assessment criteria.

36
00:03:24,150 --> 00:03:29,880
Using this,
we will be able to work out efficient and

37
00:03:30,910 --> 00:03:35,490
effective phrase mining methods, okay.

38
00:03:35,490 --> 00:03:41,430
We are going to introduce two interesting
methods developed just recently.

39
00:03:41,430 --> 00:03:47,160
One is ToPMine, is mining quality
phrases without training date.

40
00:03:47,160 --> 00:03:52,600
This one was developed by
Ahmed El-Kishky and his collaborators.

41
00:03:52,600 --> 00:03:58,630
The second one was SegPhrase, is mining
quality phrases with tiny training sets

42
00:04:00,960 --> 00:04:05,120
has been developed by Jialu Liu and
his collaborators.